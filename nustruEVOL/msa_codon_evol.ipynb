{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "from ete3 import Tree\n",
    "\n",
    "from pycirclize import Circos\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and map the Codon rarity at each position of a multiple sequence alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the codon rarity at each position of a multiple sequence alignment:\n",
    "CRS = Codon Rarity Score, AA = Amino Acid, occ = Occurence, f_c = Frequency of codon, len = Length, aln = Alignment, gaps = Gaps, n_aln = Number of sequences in the alignment\n",
    "$$ CRS_{position}= {\\sum \\limits _{AA_{AA}} ^{n_{aln}}(\\sum \\limits _{occ=1} ^{n_{aln}} {AA_{occ}} * f_c) \\over {len_{total}(alignment)} - (gaps)} $$\n",
    "$$ f_c = { \\sum n_c \\over \\sum n_{AA} } * { 1 \\over n_{cAA} } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_file = \"/Users/dominiquefastus/Downloads/nustruTREE/MSA/peptM7_nustru_secstru_filtered_protein_aligned.fasta\" \n",
    "nt_fasta_file = None \n",
    "nustruDB = \"/Users/dominiquefastus/master_project/Data/protFAMS/peptM7/peptM7_nustru_secstru_filtered.csv\" \n",
    "tree_file = \"/Users/dominiquefastus/master_project/NuStru/nustruEVOL/Tools/rerooted_tree_file.nwk\"\n",
    "output_path = \"/Users/dominiquefastus/master_project/NuStru/nustruEVOL/\" \n",
    "working_name = os.path.basename(alignment_file)\n",
    "family_name = None\n",
    "\n",
    "job_id = uuid.uuid4()\n",
    "\n",
    "nustrudb = pd.read_csv(nustruDB)\n",
    "protein_alignment = AlignIO.read(alignment_file, \"fasta\")\n",
    "if nt_fasta_file is not None:\n",
    "    nucleotide_sequences = SeqIO.parse(nt_fasta_file, \"fasta\")\n",
    "else:\n",
    "    for record in protein_alignment:\n",
    "        try:\n",
    "            nucleotide_id = nustrudb.loc[nustrudb[\"primary_id\"] == record.id][\"nucleotide_id\"].values[0]\n",
    "            nucleotide_sequence = nustrudb.loc[nustrudb[\"primary_id\"] == record.id][\"nucleotide_sequence\"].values[0]\n",
    "            with open(f\"{output_path}/{job_id}_nucleotide_sequences.fasta\", \"a\") as f:\n",
    "                f.write(f\">{nucleotide_id}\\n{nucleotide_sequence}\\n\")\n",
    "        except:\n",
    "            continue\n",
    "    nucleotide_sequences = SeqIO.parse(f\"{output_path}/{job_id}_nucleotide_sequences.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_array(fasta, align_to=None, codon=False):\n",
    "    all_seqs = []\n",
    "    all_ids = []\n",
    "    \n",
    "    if codon:\n",
    "        for (ind,record) in enumerate(fasta):\n",
    "            all_seqs.append(list(str(record.seq)))\n",
    "            all_seqs[ind] = [''.join(map(str, all_seqs[ind][i:i+3])) for i in range(0, len(all_seqs[ind]), 3)]\n",
    "            \n",
    "    else:           \n",
    "        for record in fasta:\n",
    "            all_seqs.append(list(str(record.seq)))\n",
    "            all_ids.append(record.id)\n",
    "        \n",
    "        all_seqs = np.array(all_seqs)\n",
    "\n",
    "    if align_to is not None:\n",
    "        gap_indeces = np.where(align_to == '-')\n",
    "        \n",
    "        for gap_index in zip(gap_indeces[0], gap_indeces[1]):\n",
    "            all_seqs[gap_index[0]].insert(gap_index[1], '---')\n",
    "        \n",
    "        all_seqs = np.array(all_seqs)\n",
    "        # deleting stop codons as no protein assigned to them\n",
    "        all_seqs = np.delete(all_seqs, -1, axis=1)\n",
    "    \n",
    "    all_ids = np.array(all_ids).reshape(len(all_ids), 1)\n",
    "    \n",
    "    return all_seqs\n",
    "\n",
    "def filter_columns_by_gap_threshold(seq_arr, threshold=0.5):\n",
    "    n_rows = seq_arr.shape[0]\n",
    "    valid_columns = []\n",
    "    deleted_columns = []\n",
    "    \n",
    "    # Iterate through each column index\n",
    "    for col_index in range(seq_arr.shape[1]):\n",
    "        gap_count = np.sum(seq_arr[:, col_index] == 0)\n",
    "        gap_percentage = gap_count / n_rows\n",
    "        \n",
    "        # Append column index based on gap percentage\n",
    "        if gap_percentage <= threshold:\n",
    "            valid_columns.append(col_index)\n",
    "        else:\n",
    "            deleted_columns.append(col_index)\n",
    "    \n",
    "    filtered_seq_arr = seq_arr[:, valid_columns]\n",
    "    \n",
    "    # Return the filtered array and the list of deleted columns' indices\n",
    "    return filtered_seq_arr, deleted_columns\n",
    "\n",
    "def cub_msa_table(prot_seq_arr=None, cod_seq_arr=None):\n",
    "    cub_table = {\n",
    "    # '*': {'TAA': None, 'TAG': None, 'TGA': None}, ignoring stop codons\n",
    "    'A': {'GCA': None, 'GCC': None, 'GCG': None, 'GCT': None},\n",
    "    'C': {'TGC': None, 'TGT': None},\n",
    "    'D': {'GAC': None, 'GAT': None},\n",
    "    'E': {'GAA': None, 'GAG': None},\n",
    "    'F': {'TTC': None, 'TTT': None},\n",
    "    'G': {'GGA': None, 'GGC': None, 'GGG': None, 'GGT': None},\n",
    "    'H': {'CAC': None, 'CAT': None},\n",
    "    'I': {'ATA': None, 'ATC': None, 'ATT': None},\n",
    "    'K': {'AAA': None, 'AAG': None},\n",
    "    'L': {'CTA': None, 'CTC': None, 'CTG': None, 'CTT': None, 'TTA': None, 'TTG': None},\n",
    "    'M': {'ATG': None},\n",
    "    'N': {'AAC': None, 'AAT': None},\n",
    "    'P': {'CCA': None, 'CCC': None, 'CCG': None, 'CCT': None},\n",
    "    'Q': {'CAA': None, 'CAG': None},\n",
    "    'R': {'AGA': None, 'AGG': None, 'CGA': None, 'CGC': None, 'CGG': None, 'CGT': None},\n",
    "    'S': {'AGC': None, 'AGT': None, 'TCA': None, 'TCC': None, 'TCG': None, 'TCT': None},\n",
    "    'T': {'ACA': None, 'ACC': None, 'ACG': None, 'ACT': None},\n",
    "    'V': {'GTA': None, 'GTC': None, 'GTG': None, 'GTT': None},\n",
    "    'W': {'TGG': None},\n",
    "    'Y': {'TAC': None, 'TAT': None}}\n",
    "    \n",
    "    for aa in cub_table.keys():\n",
    "        n_AA = np.count_nonzero(prot_seq_arr == aa)\n",
    "                \n",
    "        nc_AA = len(cub_table[aa].keys())\n",
    "        \n",
    "        for codon in cub_table[aa].keys():\n",
    "            nc = np.count_nonzero(cod_seq_arr == codon)\n",
    "            \n",
    "            fc =(nc / n_AA) * 1/nc_AA\n",
    "\n",
    "            cub_table[aa][codon] = round(fc,6)\n",
    "        \n",
    "    return cub_table\n",
    "\n",
    "def map_rarity(protein_alignment, nustrudb, cu_table):\n",
    "    codon_position_start = 0\n",
    "    alignment_value_matrix = np.zeros((len(protein_alignment), len(protein_alignment[0])))\n",
    "    seq_name = [seq.id for seq in protein_alignment]\n",
    "    seq_pos = [i for i in range(len(protein_alignment[0]))]\n",
    "\n",
    "    sart_count = [0 for i in range(len(seq_name))]\n",
    "    pos_count_dict = {seq_name[i]: 0 for i in range(len(seq_name))}\n",
    "    for position in range(len(protein_alignment[0])):\n",
    "\n",
    "        for i, (aa, seq) in enumerate(zip(protein_alignment[:,position],seq_name)):\n",
    "            if aa == '-':\n",
    "                alignment_value_matrix[i, position] = 0\n",
    "                pos_count_dict[seq] += 1\n",
    "            else:\n",
    "                prot_position = pos_count_dict[seq]\n",
    "                position_adj = position - prot_position\n",
    "                \n",
    "                sequence = nustrudb[nustrudb[\"primary_id\"] == seq][\"nucleotide_sequence\"].values[0]\n",
    "                alignment_value_matrix[i, position] = cu_table[aa][sequence[position_adj*3:position_adj*3+3].upper()]\n",
    "\n",
    "    residue_sum = []\n",
    "    for col_mean in np.sum(alignment_value_matrix, axis=0):\n",
    "        residue_sum.append(col_mean / len(seq_name))\n",
    "        \n",
    "    residue_max = []\n",
    "    for col_max in np.max(alignment_value_matrix, axis=0):\n",
    "        residue_max.append(col_max)\n",
    "        \n",
    "    sequence_sum = {}\n",
    "    for col_mean, name in zip(np.sum(alignment_value_matrix, axis=1), seq_name):\n",
    "        sequence_sum[name] = round((col_mean / len(alignment_value_matrix[0])), 5)\n",
    "    \n",
    "    return alignment_value_matrix, seq_name, seq_pos, residue_sum, residue_max, sequence_sum\n",
    "\n",
    "def sum_distances_to_root(tree):\n",
    "    leaf_distances = {}\n",
    "    for leaf in tree.iter_leaves():\n",
    "        current, distance_sum = leaf, 0\n",
    "        while not current.is_root():\n",
    "            distance_sum += current.dist\n",
    "            current = current.up\n",
    "        leaf_distances[leaf.name] = round(distance_sum, 5)\n",
    "    return leaf_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform alignment and sequences to arrays and align the gaps if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seqs_protein = fasta_to_array(protein_alignment)\n",
    "all_seqs_nt = fasta_to_array(fasta=nucleotide_sequences, align_to=all_seqs_protein, codon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_seqs_protein.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the codon frequency for each amino acid based on the alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ f_c = { \\sum n_c \\over \\sum n_{AA} } * { 1 \\over n_{cAA} } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cub_msa_table(prot_seq_arr=None, cod_seq_arr=None):\n",
    "    cub_table = {\n",
    "    # '*': {'TAA': None, 'TAG': None, 'TGA': None}, ignoring stop codons\n",
    "    'A': {'GCA': None, 'GCC': None, 'GCG': None, 'GCT': None},\n",
    "    'C': {'TGC': None, 'TGT': None},\n",
    "    'D': {'GAC': None, 'GAT': None},\n",
    "    'E': {'GAA': None, 'GAG': None},\n",
    "    'F': {'TTC': None, 'TTT': None},\n",
    "    'G': {'GGA': None, 'GGC': None, 'GGG': None, 'GGT': None},\n",
    "    'H': {'CAC': None, 'CAT': None},\n",
    "    'I': {'ATA': None, 'ATC': None, 'ATT': None},\n",
    "    'K': {'AAA': None, 'AAG': None},\n",
    "    'L': {'CTA': None, 'CTC': None, 'CTG': None, 'CTT': None, 'TTA': None, 'TTG': None},\n",
    "    'M': {'ATG': None},\n",
    "    'N': {'AAC': None, 'AAT': None},\n",
    "    'P': {'CCA': None, 'CCC': None, 'CCG': None, 'CCT': None},\n",
    "    'Q': {'CAA': None, 'CAG': None},\n",
    "    'R': {'AGA': None, 'AGG': None, 'CGA': None, 'CGC': None, 'CGG': None, 'CGT': None},\n",
    "    'S': {'AGC': None, 'AGT': None, 'TCA': None, 'TCC': None, 'TCG': None, 'TCT': None},\n",
    "    'T': {'ACA': None, 'ACC': None, 'ACG': None, 'ACT': None},\n",
    "    'V': {'GTA': None, 'GTC': None, 'GTG': None, 'GTT': None},\n",
    "    'W': {'TGG': None},\n",
    "    'Y': {'TAC': None, 'TAT': None}}\n",
    "    \n",
    "    for aa in cub_table.keys():\n",
    "           \n",
    "        # total number of the amino acid or total number of codon for the amino acid\n",
    "        n_AA = np.count_nonzero(prot_seq_arr == aa)\n",
    "                \n",
    "        # total number of codons for each amino acid\n",
    "        nc_AA = len(cub_table[aa].keys())\n",
    "        \n",
    "        for codon in cub_table[aa].keys():\n",
    "            \n",
    "            # number of a codon in the alignment for each amino acid\n",
    "            nc = np.count_nonzero(cod_seq_arr == codon)\n",
    "            \n",
    "            # caluclate the frequency of codons in the alignment for each amino acid\n",
    "            fc =(nc / n_AA) * 1/nc_AA\n",
    "            \n",
    "            \n",
    "            # round the frequency to 5 decimal places and assign it to the codon usage bias table\n",
    "            cub_table[aa][codon] = round(fc,5)\n",
    "        \n",
    "    return cub_table\n",
    "        \n",
    "cub_msa_table_ddla = cub_msa_table(prot_seq_arr=all_seqs_protein, cod_seq_arr=all_seqs_nt)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Codon Rarity Score for each position of the alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ CR_{position}= {\\sum \\limits _{AA_{AA}} ^{n_{aln}}(\\sum \\limits _{occ=1} ^{n_{aln}} {AA_{occ}} * f_c) \\over {len_{total}(alignment)} - (gaps)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cub_msa_table_ddla = cub_msa_table(prot_seq_arr=all_seqs_protein, cod_seq_arr=all_seqs_nt)\n",
    "alignment_value_matrix, seq_name, seq_pos, residue_sum, residue_max, sequence_sum = map_rarity(protein_alignment, nustrudb, cub_msa_table_ddla)\n",
    "\n",
    "\n",
    "sorted_alignment_value_matrix = np.sort(alignment_value_matrix, axis=0)\n",
    "sorted_alignment_value_matrix = np.flip(sorted_alignment_value_matrix, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f\"{output_path}/cub_msa_table_ddla.npz\", alignment_value_matrix=alignment_value_matrix, seq_name=seq_name, seq_pos=seq_pos, residue_sum=residue_sum, residue_max=residue_max, sequence_sum=sequence_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_value_matrix_filtered,deleted_columns = filter_columns_by_gap_threshold(alignment_value_matrix)\n",
    "sorted_alignment_value_matrix_filtered,deleted_columns = filter_columns_by_gap_threshold(sorted_alignment_value_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in sorted(deleted_columns, reverse=True):\n",
    "    del seq_pos[index]\n",
    "    del residue_max[index]\n",
    "    del residue_sum[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(seq_pos))\n",
    "print(len(residue_max))\n",
    "seq_pos_new = [i for i in range(len(residue_max))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def get_secstru(seq_name, seq_pos, aln_prot_arr, nustrudb):\n",
    "    secstru_dicts = []\n",
    "    for seq in seq_name:\n",
    "        secstru = nustrudb[nustrudb[\"primary_id\"] == seq][\"secondary_structure\"].values[0]\n",
    "        secstru_dicts.append(secstru)\n",
    "        \n",
    "    secstru_df = pd.DataFrame(secstru_dicts)\n",
    "    secstru_arr = secstru_df.to_numpy()\n",
    "    \n",
    "    print(aln_prot_arr)\n",
    "    \n",
    "        \n",
    "get_secstru(seq_name=seq_name, seq_pos=None, aln_prot_arr=all_seqs_protein, nustrudb=nustrudb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Codon Rarity Score for each position of the alignment in MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'x': seq_pos,\n",
    "    'y': residue_sum\n",
    "})\n",
    "\n",
    "# Compute the rolling mean with a window of 10\n",
    "df['smoothed_y'] = df['y'].rolling(window=10, center=True).mean()\n",
    "\n",
    "fig1 = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "fig1.add_trace((go.Heatmap(z=alignment_value_matrix_filtered, y=seq_name, colorscale=\"blues\", showlegend=False)), row=3, col=1)\n",
    "fig1.add_trace((go.Heatmap(z=sorted_alignment_value_matrix_filtered, y=seq_name, colorscale=\"blues\")), row=2, col=1)\n",
    "fig1.add_trace((go.Scatter(x=seq_pos_new, y=df['smoothed_y'], mode=\"lines\", line=dict(color=\"navy\"))), row=1, col=1)\n",
    "fig1['layout']['yaxis1']['visible']=True\n",
    "fig1['layout']['yaxis2']['visible']=False\n",
    "fig1['layout']['yaxis3']['visible']=False\n",
    "fig1.write_image(f\"{output_path}/{working_name}_codon_rarity_heatmap.png\")\n",
    "fig1.write_html(f\"{output_path}/{working_name}_codon_rarity_heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split1 = sorted_alignment_value_matrix_filtered[0:200,:]\n",
    "split2 = sorted_alignment_value_matrix_filtered[201:400,:]\n",
    "\n",
    "residue_sum1 = []\n",
    "for col_mean in np.sum(split1, axis=0):\n",
    "    residue_sum1.append(col_mean / len(seq_name))\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'x': seq_pos,\n",
    "    'y': residue_sum1\n",
    "})\n",
    "\n",
    "residue_sum2 = []\n",
    "for col_mean in np.sum(split2, axis=0):\n",
    "    residue_sum2.append(col_mean / len(seq_name))\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'x': seq_pos,\n",
    "    'y': residue_sum2\n",
    "})\n",
    "\n",
    "# Compute the rolling mean with a window of 10\n",
    "df1['smoothed_y'] = df1['y'].rolling(window=10, center=True).mean()\n",
    "df2['smoothed_y'] = df2['y'].rolling(window=10, center=True).mean()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_scatter(x=seq_pos_new, y=df1['smoothed_y'], mode=\"lines\", line=dict(color=\"blue\"))\n",
    "fig.add_scatter(x=seq_pos_new, y=df2['smoothed_y'], mode=\"lines\", line=dict(color=\"red\"))\n",
    "fig.write_image(f\"{output_path}/seperate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "dendro = ff.create_dendrogram(alignment_value_matrix_filtered, labels=seq_name, orientation='right')\n",
    "heatmap_labels = dendro['layout']['yaxis']['ticktext']\n",
    "\n",
    "# Create and add the heatmap in the second column\n",
    "heatmap = go.Heatmap(z=alignment_value_matrix_filtered, x=seq_pos_new, y=heatmap_labels,  colorscale=\"blues\")\n",
    "\n",
    "fig2 = make_subplots(rows=1, cols=2, shared_yaxes=True, shared_xaxes=True,\n",
    "                    horizontal_spacing=0.01, subplot_titles=(\"Dendrogram\", \"Heatmap\"))\n",
    "\n",
    "for data in dendro['data']:\n",
    "    fig2.add_trace(data, row=1, col=1)\n",
    "\n",
    "fig2.add_trace(heatmap, row=1, col=2)\n",
    "fig2.update_layout(width=1000, height=800, showlegend=False)\n",
    "fig2.write_image(f\"{output_path}/codon_rarity_dendrogram_heatmap.png\")\n",
    "fig2.write_html(f\"{output_path}/codon_rarity_dendrogram_heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "tree = Tree(tree_file)\n",
    "leaf_distances = sum_distances_to_root(tree)\n",
    "x_values = [leaf_distances[key] for key in sorted(leaf_distances)]\n",
    "y_values = [sequence_sum[key] for key in sorted(sequence_sum)]\n",
    "\n",
    "x_array = np.array(x_values)\n",
    "y_array = np.array(y_values)\n",
    "\n",
    "pearson_corr, _ = stats.pearsonr(x_array, y_array)\n",
    "spearman_corr, _ = stats.spearmanr(x_array, y_array)\n",
    "kendall_corr, _ = stats.kendalltau(x_array, y_array)\n",
    "\n",
    "slope, intercept, r, p, stderr = stats.linregress(x_array, y_array)\n",
    "print(r)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.style.use('ggplot')\n",
    "sns.regplot(x=x_values, y=y_values,\n",
    "            scatter_kws={'color': 'blue', 'alpha': 0.5}, \n",
    "            line_kws={'color': 'navy', })\n",
    "plt.text(0.02, -0.1, f\"Pearson Correlation: {round(pearson_corr, 5)}\\nSpearman Correlation: {round(spearman_corr, 5)}\\nKendall Correlation: {round(kendall_corr, 5)}\", fontsize=12, transform=plt.gcf().transFigure)\n",
    "plt.title('Divergence of Codon Rarity for Peptidase M7')\n",
    "plt.xlabel('Branch Lengths from Root (divergence)')\n",
    "plt.ylabel('Codon Rarity Score (sum of all residues)')\n",
    "plt.show()\n",
    "plt.savefig(f\"{output_path}/divergence_codon_rarity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequence_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Codon Rarity Change in Circle Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sectors = {}\n",
    "\n",
    "for seq in seq_name[0:10]:\n",
    "    sectors[seq] = alignment_value_matrix.shape[1]\n",
    "    \n",
    "circos = Circos(sectors, space=5)\n",
    "\n",
    "for sector in circos.sectors:\n",
    "    \n",
    "    rarity = alignment_value_matrix[seq_name[0:10].index(sector.name)]\n",
    "    # add sequence track\n",
    "    sector.text(f\"{sector.name}\", r=110, size=10)\n",
    "    track = sector.add_track((95, 100))\n",
    "    track.axis()\n",
    "    track.text(sector.name, color=\"white\", size=12)\n",
    "    track.xticks_by_interval(50)\n",
    "    \n",
    "    # add codon rarity track\n",
    "    line_track = sector.add_track((85, 95), r_pad_ratio=0.1)\n",
    "    line_track.axis()\n",
    "    line_track.line(seq_pos[0:10],rarity[0:10])\n",
    "\n",
    "all_seqs_nt = all_seqs_nt[0:10]\n",
    "reference = all_seqs_nt[0:10]\n",
    "for seq_num in range(0, len(all_seqs_nt[0:10])):\n",
    "    compare = np.tile(all_seqs_nt[seq_num], (len(all_seqs_nt), 1))\n",
    "\n",
    "    # Finding the differences\n",
    "    differences = compare != reference\n",
    "\n",
    "    # Getting the indices where the differences occur\n",
    "    diff_indices = np.where(differences)\n",
    "\n",
    "    for codon_change in zip(diff_indices[0], diff_indices[1]):\n",
    "        seq_cod =  seq_name[0:10][codon_change[0]]\n",
    "        circos.link((f\"{seq_name[0:10][0]}\", codon_change[1], codon_change[1]), (f\"{seq_name[0:10][codon_change[0]]}\", codon_change[1], codon_change[1]))\n",
    "\n",
    "fig = circos.savefig(f\"{output_path}/codon_rarity_circos.png\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dicts = []\n",
    "for seq in seq_name:\n",
    "    dicts.append(nustrudb[nustrudb[\"primary_id\"] == seq][\"secondary_structure\"].values[0].replace('\"', ''))\n",
    "\n",
    "# Map secondary structures to numerical values\n",
    "structure_to_number = {'-': 0, 'E': 1, 'H': 2, 'S': 3, 'T': 4, 'B': 5, 'G': 6, 'I': 7, 'P': 8}\n",
    "\n",
    "# Assume all dictionaries are the same length\n",
    "positions = range(1, 331)  # Update based on the actual number of positions\n",
    "\n",
    "# Initialize an empty list to store values for each position\n",
    "values = {pos: [] for pos in positions}\n",
    "\n",
    "# Fill values for each position from all dictionaries\n",
    "for d in dicts:\n",
    "    for pos, struct in d.items():\n",
    "        values[pos].append(structure_to_number[struct])\n",
    "\n",
    "# Calculate variance at each position\n",
    "variances = {pos: np.var(val) for pos, val in values.items()}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(list(variances.keys()), list(variances.values()), marker='o')\n",
    "plt.title('Variance of Secondary Structure Along Residue Positions')\n",
    "plt.xlabel('Residue Position')\n",
    "plt.ylabel('Variance')\n",
    "plt.grid(True)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and map the Codon conservation at each position of a multiple sequence alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the codon conservation at each position of a multiple sequence alignment:\n",
    "CCS = Codon Conservation Score,\n",
    "$$ CCS_{position} = ? $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CodonTree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
