{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import uuid\n",
    "import ast\n",
    "import os\n",
    "\n",
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO, Phylo\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from collections import Counter\n",
    "\n",
    "from ete3 import Tree, TreeStyle, NodeStyle, faces, AttrFace\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and map the Codon rarity at each position of a multiple sequence alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the codon rarity at each position of a multiple sequence alignment:\n",
    "CRS = Codon Rarity Score, AA = Amino Acid, occ = Occurence, f_c = Frequency of codon, len = Length, aln = Alignment, gaps = Gaps, n_aln = Number of sequences in the alignment\n",
    "$$ CRS_{position}= {\\sum \\limits _{AA_{AA}} ^{n_{aln}}(\\sum \\limits _{occ=1} ^{n_{aln}} {AA_{occ}} * f_c) \\over {len_{total}(alignment)} - (gaps)} $$\n",
    "$$ f_c = { \\sum n_c \\over \\sum n_{AA} } * { 1 \\over n_{cAA} } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_file = \"/Users/dominiquefastus/master_project/Data/protFAMS/peptM7/nustruTREE/MSA/peptM7_nustru_secstru_filtered_protein_aligned.fasta\"\n",
    "nt_fasta_file = None \n",
    "nustruDB = \"/Users/dominiquefastus/master_project/Data/protFAMS/peptM7/peptM7_nustru_secstru_filtered.csv\" \n",
    "tree_file = \"/Users/dominiquefastus/master_project/Data/protFAMS/peptM7/nustruTREE/TREE/rerooted_tree_file.nwk\"\n",
    "output_path = \"/Users/dominiquefastus/master_project/NuStru/nustruEVOL/\" \n",
    "working_name = os.path.basename(alignment_file)\n",
    "family_name = None\n",
    "\n",
    "job_id = uuid.uuid4()\n",
    "\n",
    "nustrudb = pd.read_csv(nustruDB)\n",
    "protein_alignment = AlignIO.read(alignment_file, \"fasta\")\n",
    "if nt_fasta_file is not None:\n",
    "    nucleotide_sequences = SeqIO.parse(nt_fasta_file, \"fasta\")\n",
    "else:\n",
    "    for record in protein_alignment:\n",
    "        try:\n",
    "            nucleotide_id = nustrudb.loc[nustrudb[\"primary_id\"] == record.id][\"nucleotide_id\"].values[0]\n",
    "            nucleotide_sequence = nustrudb.loc[nustrudb[\"primary_id\"] == record.id][\"nucleotide_sequence\"].values[0]\n",
    "            with open(f\"{output_path}/{job_id}_nucleotide_sequences.fasta\", \"a\") as f:\n",
    "                f.write(f\">{nucleotide_id}\\n{nucleotide_sequence}\\n\")\n",
    "        except:\n",
    "            continue\n",
    "    nucleotide_sequences = SeqIO.parse(f\"{output_path}/{job_id}_nucleotide_sequences.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_array(fasta, align_to=None, codon=False):\n",
    "    all_seqs = []\n",
    "    all_ids = []\n",
    "    \n",
    "    if codon:\n",
    "        for (ind,record) in enumerate(fasta):\n",
    "            all_seqs.append(list(str(record.seq)))\n",
    "            all_seqs[ind] = [''.join(map(str, all_seqs[ind][i:i+3])) for i in range(0, len(all_seqs[ind]), 3)]\n",
    "            \n",
    "    else:           \n",
    "        for record in fasta:\n",
    "            all_seqs.append(list(str(record.seq)))\n",
    "            all_ids.append(record.id)\n",
    "        \n",
    "        all_seqs = np.array(all_seqs)\n",
    "\n",
    "    if align_to is not None:\n",
    "        gap_indeces = np.where(align_to == '-')\n",
    "        \n",
    "        for gap_index in zip(gap_indeces[0], gap_indeces[1]):\n",
    "            all_seqs[gap_index[0]].insert(gap_index[1], '---')\n",
    "        \n",
    "        all_seqs = np.array(all_seqs)\n",
    "        # deleting stop codons as no protein assigned to them\n",
    "        all_seqs = np.delete(all_seqs, -1, axis=1)\n",
    "    \n",
    "    all_ids = np.array(all_ids).reshape(len(all_ids), 1)\n",
    "    \n",
    "    return all_seqs\n",
    "\n",
    "def filter_columns_by_gap_threshold(seq_arr, threshold=0.5):\n",
    "    n_rows = seq_arr.shape[0]\n",
    "    valid_columns = []\n",
    "    deleted_columns = []\n",
    "    \n",
    "    # Iterate through each column index\n",
    "    for col_index in range(seq_arr.shape[1]):\n",
    "        gap_count = np.sum(seq_arr[:, col_index] == 0)\n",
    "        gap_percentage = gap_count / n_rows\n",
    "        \n",
    "        # Append column index based on gap percentage\n",
    "        if gap_percentage <= threshold:\n",
    "            valid_columns.append(col_index)\n",
    "        else:\n",
    "            deleted_columns.append(col_index)\n",
    "    \n",
    "    filtered_seq_arr = seq_arr[:, valid_columns]\n",
    "    \n",
    "    # Return the filtered array and the list of deleted columns' indices\n",
    "    return filtered_seq_arr, deleted_columns\n",
    "\n",
    "def cub_msa_table(prot_seq_arr=None, cod_seq_arr=None):\n",
    "    cub_table = {\n",
    "    # '*': {'TAA': None, 'TAG': None, 'TGA': None}, ignoring stop codons\n",
    "    'A': {'GCA': None, 'GCC': None, 'GCG': None, 'GCT': None},\n",
    "    'C': {'TGC': None, 'TGT': None},\n",
    "    'D': {'GAC': None, 'GAT': None},\n",
    "    'E': {'GAA': None, 'GAG': None},\n",
    "    'F': {'TTC': None, 'TTT': None},\n",
    "    'G': {'GGA': None, 'GGC': None, 'GGG': None, 'GGT': None},\n",
    "    'H': {'CAC': None, 'CAT': None},\n",
    "    'I': {'ATA': None, 'ATC': None, 'ATT': None},\n",
    "    'K': {'AAA': None, 'AAG': None},\n",
    "    'L': {'CTA': None, 'CTC': None, 'CTG': None, 'CTT': None, 'TTA': None, 'TTG': None},\n",
    "    'M': {'ATG': None},\n",
    "    'N': {'AAC': None, 'AAT': None},\n",
    "    'P': {'CCA': None, 'CCC': None, 'CCG': None, 'CCT': None},\n",
    "    'Q': {'CAA': None, 'CAG': None},\n",
    "    'R': {'AGA': None, 'AGG': None, 'CGA': None, 'CGC': None, 'CGG': None, 'CGT': None},\n",
    "    'S': {'AGC': None, 'AGT': None, 'TCA': None, 'TCC': None, 'TCG': None, 'TCT': None},\n",
    "    'T': {'ACA': None, 'ACC': None, 'ACG': None, 'ACT': None},\n",
    "    'V': {'GTA': None, 'GTC': None, 'GTG': None, 'GTT': None},\n",
    "    'W': {'TGG': None},\n",
    "    'Y': {'TAC': None, 'TAT': None}}\n",
    "    \n",
    "    for aa in cub_table.keys():\n",
    "        n_AA = np.count_nonzero(prot_seq_arr == aa)\n",
    "                \n",
    "        nc_AA = len(cub_table[aa].keys())\n",
    "        \n",
    "        for codon in cub_table[aa].keys():\n",
    "            nc = np.count_nonzero(cod_seq_arr == codon)\n",
    "            \n",
    "            fc =(nc / n_AA) * 1/nc_AA\n",
    "\n",
    "            cub_table[aa][codon] = round(fc,6)\n",
    "        \n",
    "    return cub_table\n",
    "\n",
    "def map_rarity(protein_alignment, nustrudb, cu_table):\n",
    "    codon_position_start = 0\n",
    "    alignment_value_matrix = np.zeros((len(protein_alignment), len(protein_alignment[0])))\n",
    "    seq_name = [seq.id for seq in protein_alignment]\n",
    "    seq_pos = [i for i in range(len(protein_alignment[0]))]\n",
    "\n",
    "    sart_count = [0 for i in range(len(seq_name))]\n",
    "    pos_count_dict = {seq_name[i]: 0 for i in range(len(seq_name))}\n",
    "    for position in range(len(protein_alignment[0])):\n",
    "\n",
    "        for i, (aa, seq) in enumerate(zip(protein_alignment[:,position],seq_name)):\n",
    "            if aa == '-':\n",
    "                alignment_value_matrix[i, position] = 0\n",
    "                pos_count_dict[seq] += 1\n",
    "            else:\n",
    "                prot_position = pos_count_dict[seq]\n",
    "                position_adj = position - prot_position\n",
    "                \n",
    "                sequence = nustrudb[nustrudb[\"primary_id\"] == seq][\"nucleotide_sequence\"].values[0]\n",
    "                alignment_value_matrix[i, position] = cu_table[aa][sequence[position_adj*3:position_adj*3+3].upper()]\n",
    "\n",
    "    residue_sum = []\n",
    "    for col_mean in np.sum(alignment_value_matrix, axis=0):\n",
    "        residue_sum.append(col_mean / len(seq_name))\n",
    "        \n",
    "    residue_max = []\n",
    "    for col_max in np.max(alignment_value_matrix, axis=0):\n",
    "        residue_max.append(col_max)\n",
    "        \n",
    "    sequence_sum = {}\n",
    "    for col_mean, name in zip(np.sum(alignment_value_matrix, axis=1), seq_name):\n",
    "        sequence_sum[name] = round((col_mean / len(alignment_value_matrix[0])), 5)\n",
    "    \n",
    "    return alignment_value_matrix, seq_name, seq_pos, residue_sum, residue_max, sequence_sum\n",
    "\n",
    "def sum_distances_to_root(tree):\n",
    "    leaf_distances = {}\n",
    "    for leaf in tree.iter_leaves():\n",
    "        current, distance_sum = leaf, 0\n",
    "        while not current.is_root():\n",
    "            distance_sum += current.dist\n",
    "            current = current.up\n",
    "        leaf_distances[leaf.name] = round(distance_sum, 5)\n",
    "    return leaf_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform alignment and sequences to arrays and align the gaps if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seqs_protein = fasta_to_array(protein_alignment)\n",
    "all_seqs_nt = fasta_to_array(fasta=nucleotide_sequences, align_to=all_seqs_protein, codon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the codon frequency for each amino acid based on the alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ f_c = { \\sum n_c \\over \\sum n_{AA} } * { 1 \\over n_{cAA} } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cub_msa_table(prot_seq_arr=None, cod_seq_arr=None):\n",
    "    cub_table = {\n",
    "    # '*': {'TAA': None, 'TAG': None, 'TGA': None}, ignoring stop codons\n",
    "    'A': {'GCA': None, 'GCC': None, 'GCG': None, 'GCT': None},\n",
    "    'C': {'TGC': None, 'TGT': None},\n",
    "    'D': {'GAC': None, 'GAT': None},\n",
    "    'E': {'GAA': None, 'GAG': None},\n",
    "    'F': {'TTC': None, 'TTT': None},\n",
    "    'G': {'GGA': None, 'GGC': None, 'GGG': None, 'GGT': None},\n",
    "    'H': {'CAC': None, 'CAT': None},\n",
    "    'I': {'ATA': None, 'ATC': None, 'ATT': None},\n",
    "    'K': {'AAA': None, 'AAG': None},\n",
    "    'L': {'CTA': None, 'CTC': None, 'CTG': None, 'CTT': None, 'TTA': None, 'TTG': None},\n",
    "    'M': {'ATG': None},\n",
    "    'N': {'AAC': None, 'AAT': None},\n",
    "    'P': {'CCA': None, 'CCC': None, 'CCG': None, 'CCT': None},\n",
    "    'Q': {'CAA': None, 'CAG': None},\n",
    "    'R': {'AGA': None, 'AGG': None, 'CGA': None, 'CGC': None, 'CGG': None, 'CGT': None},\n",
    "    'S': {'AGC': None, 'AGT': None, 'TCA': None, 'TCC': None, 'TCG': None, 'TCT': None},\n",
    "    'T': {'ACA': None, 'ACC': None, 'ACG': None, 'ACT': None},\n",
    "    'V': {'GTA': None, 'GTC': None, 'GTG': None, 'GTT': None},\n",
    "    'W': {'TGG': None},\n",
    "    'Y': {'TAC': None, 'TAT': None}}\n",
    "    \n",
    "    for aa in cub_table.keys():\n",
    "           \n",
    "        # total number of the amino acid or total number of codon for the amino acid\n",
    "        n_AA = np.count_nonzero(prot_seq_arr == aa)\n",
    "                \n",
    "        # total number of codons for each amino acid\n",
    "        nc_AA = len(cub_table[aa].keys())\n",
    "        \n",
    "        for codon in cub_table[aa].keys():\n",
    "            \n",
    "            # number of a codon in the alignment for each amino acid\n",
    "            nc = np.count_nonzero(cod_seq_arr == codon)\n",
    "            \n",
    "            # caluclate the frequency of codons in the alignment for each amino acid\n",
    "            fc =(nc / n_AA) * 1/nc_AA\n",
    "            \n",
    "            \n",
    "            # round the frequency to 5 decimal places and assign it to the codon usage bias table\n",
    "            cub_table[aa][codon] = round(fc,5)\n",
    "        \n",
    "    return cub_table\n",
    "        \n",
    "cub_msa_table_ddla = cub_msa_table(prot_seq_arr=all_seqs_protein, cod_seq_arr=all_seqs_nt)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Codon Rarity Score for each position of the alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ CR_{position}= {\\sum \\limits _{AA_{AA}} ^{n_{aln}}(\\sum \\limits _{occ=1} ^{n_{aln}} {AA_{occ}} * f_c) \\over {len_{total}(alignment)} - (gaps)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cub_msa_table_ddla = cub_msa_table(prot_seq_arr=all_seqs_protein, cod_seq_arr=all_seqs_nt)\n",
    "alignment_value_matrix, seq_name, seq_pos, residue_sum, residue_max, sequence_sum = map_rarity(protein_alignment, nustrudb, cub_msa_table_ddla)\n",
    "\n",
    "\n",
    "sorted_alignment_value_matrix = np.sort(alignment_value_matrix, axis=0)\n",
    "sorted_alignment_value_matrix = np.flip(sorted_alignment_value_matrix, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(f\"{output_path}/cub_msa_table_ddla.npz\", alignment_value_matrix=alignment_value_matrix, seq_name=seq_name, seq_pos=seq_pos, residue_sum=residue_sum, residue_max=residue_max, sequence_sum=sequence_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_value_matrix_filtered,deleted_columns = filter_columns_by_gap_threshold(alignment_value_matrix)\n",
    "sorted_alignment_value_matrix_filtered,deleted_columns = filter_columns_by_gap_threshold(sorted_alignment_value_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in sorted(deleted_columns, reverse=True):\n",
    "    del seq_pos[index]\n",
    "    del residue_max[index]\n",
    "    del residue_sum[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_pos_new = [i for i in range(len(residue_max))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Codon Rarity Score for each position of the alignment in MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'x': seq_pos,\n",
    "    'y': residue_sum\n",
    "})\n",
    "\n",
    "# Compute the rolling mean with a window of 10\n",
    "df['smoothed_y'] = df['y'].rolling(window=10, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "fig1.add_trace((go.Heatmap(z=alignment_value_matrix_filtered, y=seq_name, colorscale=\"blues\", showlegend=False)), row=3, col=1)\n",
    "fig1.add_trace((go.Heatmap(z=sorted_alignment_value_matrix_filtered, y=seq_name, colorscale=\"blues\")), row=2, col=1)\n",
    "fig1.add_trace((go.Scatter(x=seq_pos_new, y=df['smoothed_y'], mode=\"lines\", line=dict(color=\"navy\"))), row=1, col=1)\n",
    "fig1['layout']['yaxis1']['visible']=True\n",
    "fig1['layout']['yaxis2']['visible']=False\n",
    "fig1['layout']['yaxis3']['visible']=False\n",
    "fig1.write_image(f\"{output_path}/{working_name}_codon_rarity_heatmap.png\")\n",
    "fig1.write_html(f\"{output_path}/{working_name}_codon_rarity_heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secondary_structure(seq_names, aln_prot_arr, nustrudb):\n",
    "    # Initialize a list to store the aligned secondary structure arrays\n",
    "    aligned_secstru_list = []\n",
    "\n",
    "    for seq in seq_names:\n",
    "        # Retrieve the secondary structure dictionary for the current sequence\n",
    "        secstru_dict = nustrudb[nustrudb[\"primary_id\"] == seq][\"secondary_structure\"].values[0]\n",
    "        \n",
    "        secstru_dict = ast.literal_eval(secstru_dict)\n",
    "        # Convert the dictionary to a list that aligns with the protein sequence length\n",
    "        max_pos = max(secstru_dict.keys())\n",
    "        secstru_list = ['-' for _ in range(max_pos)]\n",
    "        for pos, ss in secstru_dict.items():\n",
    "            secstru_list[pos - 1] = ss  # Adjust for 1-based to 0-based indexing\n",
    "        \n",
    "        # Align the secondary structure list with the protein alignment\n",
    "        aligned_secstru = []\n",
    "        secstru_idx = 0\n",
    "        \n",
    "        for aa in aln_prot_arr[seq_names.index(seq)]:\n",
    "            if aa == '-':\n",
    "                aligned_secstru.append('0')\n",
    "            else:\n",
    "                aligned_secstru.append(secstru_list[secstru_idx])\n",
    "                secstru_idx += 1\n",
    "        \n",
    "        aligned_secstru_list.append(aligned_secstru)\n",
    "    \n",
    "    # Convert the list of lists to a numpy array\n",
    "    aligned_secstru_arr = np.array(aligned_secstru_list)\n",
    "    \n",
    "    return aligned_secstru_arr\n",
    "\n",
    "def secstru_to_numeric(secstru_arr):\n",
    "    # Convert secondary structure elements to numeric values for plotting\n",
    "    secstru_numeric = []\n",
    "    for secstru in secstru_arr:\n",
    "        numeric_seq = []\n",
    "        for element in secstru:\n",
    "            if element == 'H':\n",
    "                numeric_seq.append(1)\n",
    "            elif element == 'E':\n",
    "                numeric_seq.append(2)\n",
    "            elif element == '-':\n",
    "                numeric_seq.append(3)\n",
    "            elif element == '0':\n",
    "                numeric_seq.append(0)\n",
    "            else:\n",
    "                numeric_seq.append(0)\n",
    "        secstru_numeric.append(numeric_seq)\n",
    "    return np.array(secstru_numeric)      \n",
    "\n",
    "def plot_secondary_structure_frequency(secstru_numeric, smoothed_y):\n",
    "    secstru_numeric = secstru_numeric.T  # Transpose to get positions as rows\n",
    "    positions = np.arange(secstru_numeric.shape[0])\n",
    "    \n",
    "    # Calculate the frequency of each secondary structure type at each position\n",
    "    freq_H = np.sum(secstru_numeric == 1, axis=1) / secstru_numeric.shape[1]\n",
    "    freq_E = np.sum(secstru_numeric == 2, axis=1) / secstru_numeric.shape[1]\n",
    "    freq_C = np.sum(secstru_numeric == 3, axis=1) / secstru_numeric.shape[1]\n",
    "    freq_0 = np.sum(secstru_numeric == 0, axis=1) / secstru_numeric.shape[1]\n",
    "    \n",
    "    # Set up the grid for the plots\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    gs = GridSpec(2, 1, height_ratios=[3, 1])\n",
    "\n",
    "    # Plotting the frequencies and smoothed Y on the top plot\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax1.plot(positions, freq_H, label='Helix (H)')\n",
    "    ax1.plot(positions, freq_E, label='Sheet (E)')\n",
    "    ax1.plot(positions, freq_C, label='Coil (C)')\n",
    "    ax1.plot(positions, freq_0, label='Gap (0)')\n",
    "    ax1.plot(positions, smoothed_y, label='Smoothed Y', linewidth=2, linestyle='--')\n",
    "\n",
    "    ax1.set_xlabel('Position')\n",
    "    ax1.set_ylabel('Frequency / Smoothed Y')\n",
    "    ax1.set_title('Frequency of Secondary Structure Types Over Position with Smoothed Y')\n",
    "    ax1.legend()\n",
    "\n",
    "\n",
    "    # Plotting the frequencies as a bar plot on the bottom plot\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    width = 0.2  # Width of the bars\n",
    "\n",
    "    '''\n",
    "    # Plotting the frequencies as a bar plot\n",
    "    ax2.bar(positions, freq_H, width, alpha=0.6, color='blue', label='Helix (H)')\n",
    "    ax2.bar(positions, freq_E, width, alpha=0.6, color='orange', label='Sheet (E)')\n",
    "    ax2.bar(positions, freq_C, width, alpha=0.6, color='green', label='Coil (C)')\n",
    "    ax2.bar(positions, freq_0, width, alpha=0.6, color='red', label='Gap (0)')\n",
    "\n",
    "    ax2.set_xlabel('Position')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('Frequency of Secondary Structure Types Over Position (Bar Plot)')\n",
    "    ax2.legend()'''\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"secondary_structure_peptm7_no_gaps\")\n",
    "\n",
    "aligned_secstru_arr = get_secondary_structure(seq_name, all_seqs_protein, nustrudb)\n",
    "secstru_numeric = secstru_to_numeric(aligned_secstru_arr)\n",
    "secstru_numeric_ng = np.delete(secstru_numeric, deleted_columns, axis=1)\n",
    "plot_secondary_structure_frequency(secstru_numeric_ng, df['smoothed_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split1 = sorted_alignment_value_matrix_filtered[0:200,:]\n",
    "split2 = sorted_alignment_value_matrix_filtered[201:400,:]\n",
    "\n",
    "residue_sum1 = []\n",
    "for col_mean in np.sum(split1, axis=0):\n",
    "    residue_sum1.append(col_mean / len(seq_name))\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'x': seq_pos,\n",
    "    'y': residue_sum1\n",
    "})\n",
    "\n",
    "residue_sum2 = []\n",
    "for col_mean in np.sum(split2, axis=0):\n",
    "    residue_sum2.append(col_mean / len(seq_name))\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'x': seq_pos,\n",
    "    'y': residue_sum2\n",
    "})\n",
    "\n",
    "# Compute the rolling mean with a window of 10\n",
    "df1['smoothed_y'] = df1['y'].rolling(window=10, center=True).mean()\n",
    "df2['smoothed_y'] = df2['y'].rolling(window=10, center=True).mean()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_scatter(x=seq_pos_new, y=df1['smoothed_y'], mode=\"lines\", line=dict(color=\"blue\"))\n",
    "fig.add_scatter(x=seq_pos_new, y=df2['smoothed_y'], mode=\"lines\", line=dict(color=\"red\"))\n",
    "fig.write_image(f\"{output_path}/seperate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendro = ff.create_dendrogram(alignment_value_matrix_filtered, labels=seq_name, orientation='right')\n",
    "heatmap_labels = dendro['layout']['yaxis']['ticktext']\n",
    "\n",
    "# Create and add the heatmap in the second column\n",
    "heatmap = go.Heatmap(z=alignment_value_matrix_filtered, x=seq_pos_new, y=heatmap_labels,  colorscale=\"blues\")\n",
    "\n",
    "fig2 = make_subplots(rows=1, cols=2, shared_yaxes=True, shared_xaxes=True,\n",
    "                    horizontal_spacing=0.01, subplot_titles=(\"Dendrogram\", \"Heatmap\"))\n",
    "\n",
    "for data in dendro['data']:\n",
    "    fig2.add_trace(data, row=1, col=1)\n",
    "\n",
    "fig2.add_trace(heatmap, row=1, col=2)\n",
    "fig2.update_layout(width=1000, height=800, showlegend=False)\n",
    "fig2.write_image(f\"{output_path}/codon_rarity_dendrogram_heatmap.png\")\n",
    "fig2.write_html(f\"{output_path}/codon_rarity_dendrogram_heatmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phylogenetic tree analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree(tree_file)\n",
    "leaf_distances = sum_distances_to_root(tree)\n",
    "x_values = [leaf_distances[key] for key in sorted(leaf_distances)]\n",
    "y_values = [sequence_sum[key] for key in sorted(sequence_sum)]\n",
    "\n",
    "x_array = np.array(x_values)\n",
    "y_array = np.array(y_values)\n",
    "\n",
    "pearson_corr, _ = stats.pearsonr(x_array, y_array)\n",
    "spearman_corr, _ = stats.spearmanr(x_array, y_array)\n",
    "kendall_corr, _ = stats.kendalltau(x_array, y_array)\n",
    "\n",
    "slope, intercept, r, p, stderr = stats.linregress(x_array, y_array)\n",
    "print(r)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.style.use('ggplot')\n",
    "sns.regplot(x=x_values, y=y_values,\n",
    "            scatter_kws={'color': 'blue', 'alpha': 0.5}, \n",
    "            line_kws={'color': 'navy', })\n",
    "plt.text(0.02, -0.1, f\"Pearson Correlation: {round(pearson_corr, 5)}\\nSpearman Correlation: {round(spearman_corr, 5)}\\nKendall Correlation: {round(kendall_corr, 5)}\", fontsize=12, transform=plt.gcf().transFigure)\n",
    "plt.title('Divergence of Codon Rarity for IS1 element transposase InsA')\n",
    "plt.xlabel('Branch Lengths from Root (divergence)')\n",
    "plt.ylabel('Codon Rarity Score (sum of all residues)')\n",
    "\n",
    "plt.savefig(f\"{output_path}/divergence_codon_rarity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree(tree_file)\n",
    "\n",
    "# Dictionary with leaf name and value\n",
    "leaf_values = sequence_sum\n",
    "\n",
    "# Function to get a color based on the value\n",
    "def get_color(value, min_val, max_val):\n",
    "    # Normalize the value between 0 and 1\n",
    "    norm_val = (value - min_val) / (max_val - min_val)\n",
    "    # Generate a color from green to red\n",
    "    r = int(255 * norm_val)\n",
    "    g = int(255 * (1 - norm_val))\n",
    "    return f'#{r:02x}{g:02x}00'\n",
    "\n",
    "# Determine min and max values for normalization\n",
    "min_val = min(leaf_values.values())\n",
    "max_val = max(leaf_values.values())\n",
    "\n",
    "# Apply styles to the tree nodes\n",
    "for leaf in tree:\n",
    "    if leaf.name in leaf_values:\n",
    "        value = leaf_values[leaf.name]\n",
    "        color = get_color(value, min_val, max_val)\n",
    "        \n",
    "        # Set node style\n",
    "        style = NodeStyle()\n",
    "        style[\"fgcolor\"] = color\n",
    "        style[\"size\"] = 10\n",
    "        \n",
    "        leaf.set_style(style)\n",
    "        \n",
    "# Define a tree style\n",
    "ts = TreeStyle()\n",
    "# ts.mode = \"c\"\n",
    "ts.show_leaf_name = False\n",
    "ts.show_branch_length = False\n",
    "ts.show_branch_support = False\n",
    "#ts.scale = 20\n",
    "#ts.branch_vertical_margin = 50\n",
    "\n",
    "# Render the tree\n",
    "# tree.render('%%inline', w=1400, h=1800, tree_style=ts)\n",
    "tree.render('peptM7_tree.png', w=1400, h=1800, tree_style=ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codon_data = nustrudb\n",
    "\n",
    "# Extract nucleotide sequences\n",
    "nucleotide_sequences = codon_data.set_index('nucleotide_id')['nucleotide_sequence'].to_dict()\n",
    "\n",
    "\n",
    "# Function to extract codons from nucleotide sequences\n",
    "def extract_codons(nucleotide_sequences):\n",
    "    codon_counter = Counter()\n",
    "    for seq in nucleotide_sequences.values():\n",
    "        for i in range(0, len(seq) - 2, 3):\n",
    "            codon = seq[i:i+3]\n",
    "            if len(codon) == 3:\n",
    "                codon_counter[codon] += 1\n",
    "    return codon_counter\n",
    "\n",
    "codon_counter = extract_codons(nucleotide_sequences)\n",
    "\n",
    "# Determine common and rare codons\n",
    "total_codons = sum(codon_counter.values())\n",
    "threshold = total_codons * 0.01  # 1% threshold\n",
    "common_codons = {codon for codon, count in codon_counter.items() if count >= threshold}\n",
    "rare_codons = set(codon_counter.keys()) - common_codons\n",
    "\n",
    "# Step 2: Read alignment and tree data\n",
    "alignment = AlignIO.read(alignment_file, 'fasta')\n",
    "tree = Tree(tree_file, format=1)\n",
    "\n",
    "# Function to map codon rarity\n",
    "def map_codon_rarity(sequences, common_codons, rare_codons):\n",
    "    rarity_map = {}\n",
    "    for header, seq in sequences.items():\n",
    "        rarity_status = []\n",
    "        for i in range(0, len(seq) - 2, 3):\n",
    "            codon = seq[i:i+3]\n",
    "            if codon in common_codons:\n",
    "                rarity_status.append('common')\n",
    "            elif codon in rare_codons:\n",
    "                rarity_status.append('rare')\n",
    "            else:\n",
    "                rarity_status.append('unknown')\n",
    "        rarity_map[header] = rarity_status\n",
    "    return rarity_map\n",
    "\n",
    "codon_rarity_map = map_codon_rarity(nucleotide_sequences, common_codons, rare_codons)\n",
    "\n",
    "# Function to assign rarity status to internal nodes using maximum parsimony\n",
    "def ancestral_reconstruction(tree, codon_rarity_map):\n",
    "    for leaf in tree.iter_leaves():\n",
    "        leaf.add_feature(\"rarity\", codon_rarity_map.get(leaf.name, ['unknown'] * len(next(iter(codon_rarity_map.values())))))\n",
    "\n",
    "    def reconcile_rarity(node):\n",
    "        if not node.is_leaf():\n",
    "            children = node.get_children()\n",
    "            child_rarities = [child.rarity for child in children if hasattr(child, \"rarity\")]\n",
    "            if child_rarities:\n",
    "                transposed_rarities = list(zip(*child_rarities))\n",
    "                majority_rarities = [max(set(column), key=column.count) for column in transposed_rarities]\n",
    "                node.add_feature(\"rarity\", majority_rarities)\n",
    "\n",
    "    for node in tree.traverse(\"postorder\"):\n",
    "        reconcile_rarity(node)\n",
    "\n",
    "ancestral_reconstruction(tree, codon_rarity_map)\n",
    "\n",
    "def layout(node):\n",
    "    if node.is_leaf():\n",
    "        faces.add_face_to_node(AttrFace(\"name\", fsize=10), node, column=0, position=\"branch-right\")\n",
    "    if hasattr(node, \"rarity\"):\n",
    "        rarity_face = faces.TextFace(','.join(node.rarity), fsize=8)\n",
    "        faces.add_face_to_node(rarity_face, node, column=1, position=\"branch-right\")\n",
    "\n",
    "ts = TreeStyle()\n",
    "ts.layout_fn = layout\n",
    "ts.show_leaf_name = False\n",
    "ts.title.add_face(faces.TextFace(\"Phylogenetic Tree with Codon Rarity\", fsize=12), column=0)\n",
    "\n",
    "tree.render('%%inline', w=1400, h=1800, tree_style=ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and map the Codon conservation at each position of a multiple sequence alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the codon conservation at each position of a multiple sequence alignment:\n",
    "CCS = Codon Conservation Score,\n",
    "$$ CCS_{position} = ? $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CodonTree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
