{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform KL divergence analysis for synonymous codons and their probability to appear in correlation with a specific secondary structure element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Example/examples_organism/example_nustru_ecoli.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m savefig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# define if figures should be saved\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#load nustrudb data, the pandas dataframe with structure and nucleotide information\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m nustrudb \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Example/examples_organism/example_nustru_ecoli.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msecondary_structure\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/CodonFold/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/CodonFold/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/CodonFold/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/CodonFold/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/CodonFold/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Example/examples_organism/example_nustru_ecoli.csv'"
     ]
    }
   ],
   "source": [
    "savefig = False # define if figures should be saved\n",
    "\n",
    "#load nustrudb data, the pandas dataframe with structure and nucleotide information\n",
    "nustrudb = pd.read_csv('/Example/examples_organism/example_nustru_ecoli.csv', converters={'secondary_structure': ast.literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions and codon table needed for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time we need the amino acids as keys and the codons as list values\n",
    "# by that it's possible to use a counter\n",
    "standard_codons = {\n",
    "    'A': ['GCT', 'GCC', 'GCA', 'GCG'], \n",
    "    'C': ['TGT', 'TGC'],             \n",
    "    'D': ['GAT', 'GAC'],              \n",
    "    'E': ['GAA', 'GAG'],               \n",
    "    'F': ['TTT', 'TTC'],               \n",
    "    'G': ['GGT', 'GGC', 'GGA', 'GGG'],  \n",
    "    'H': ['CAT', 'CAC'],            \n",
    "    'I': ['ATT', 'ATC', 'ATA'],        \n",
    "    'K': ['AAA', 'AAG'],             \n",
    "    'L': ['TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG'],  \n",
    "    'M': ['ATG'],                   \n",
    "    'N': ['AAT', 'AAC'],              \n",
    "    'P': ['CCT', 'CCC', 'CCA', 'CCG'], \n",
    "    'Q': ['CAA', 'CAG'],               \n",
    "    'R': ['CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], \n",
    "    'S': ['TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'], \n",
    "    'T': ['ACT', 'ACC', 'ACA', 'ACG'], \n",
    "    'V': ['GTT', 'GTC', 'GTA', 'GTG'],  \n",
    "    'W': ['TGG'],                      \n",
    "    'Y': ['TAT', 'TAC']                 \n",
    "}\n",
    "\n",
    "def split_into_codons(sequence):\n",
    "    \"\"\"Split the sequence into codons\"\"\"\n",
    "    # codons are a subset of 3 nucleotide, so we check again if the sequence is divisible by 3\n",
    "    # due to previous filtering, this should be always the case\n",
    "    return [sequence[i:i+3] for i in range(0, len(sequence), 3) if len(sequence[i:i+3]) == 3]\n",
    "    \n",
    "def count_codons(nustrudb):\n",
    "    \"\"\"Count the codons and structure for amino acids\"\"\"\n",
    "    \n",
    "    # set a dictionary with counter values for the syononymous codons\n",
    "    # later the count present in the whole dataset will be stored here\n",
    "    aa_codon_counts = {aa: Counter() for aa in standard_codons}\n",
    "\n",
    "    # set a dictionary with counter values for the structure present in correlation with a codon\n",
    "    aa_structure_counts = {aa: {'Helix': Counter(), 'Coil': Counter(), 'Sheet': Counter()} for aa in standard_codons}\n",
    "\n",
    "    # now loop over each row in the database and count the codon in appearance with a structure\n",
    "    for _, row in nustrudb.iterrows():\n",
    "        # split the nucleotide sequence into codons\n",
    "        # set both the codons and structure to variables\n",
    "        codons = split_into_codons(row['nucleotide_sequence'])\n",
    "        structure = row['secondary_structure']\n",
    "\n",
    "        for i, codon in enumerate(codons):\n",
    "            # loop over the codons present in the nucleotide sequence\n",
    "\n",
    "            for aa, codons_list in standard_codons.items():\n",
    "                # also loop over all codons and amino acids in the scripts\n",
    "                if codon in codons_list:\n",
    "                    # if the codon is in the synonymous codon of a protein, \n",
    "                    # then count the codon for this amino acid\n",
    "                    aa_codon_counts[aa][codon] += 1\n",
    "                    # then we count the codons for each structure\n",
    "                    if i + 1 in structure:\n",
    "                        # since the dictionary starts at 1 and not 0, we add 1 to the iter\n",
    "                        # the structures are also aggregated based on their type here\n",
    "                        # the underlyi\n",
    "                        if structure[i + 1] == 'H' or structure[i + 1] == 'I' or structure[i + 1] == 'G':\n",
    "                            aa_structure_counts[aa]['Helix'][codon] += 1\n",
    "                        elif structure[i + 1] == '-' or structure[i + 1] == 'T' or structure[i + 1] == 'S':\n",
    "                            aa_structure_counts[aa]['Coil'][codon] += 1\n",
    "                        elif structure[i + 1] == 'E' or structure[i + 1] == 'B':\n",
    "                            aa_structure_counts[aa]['Sheet'][codon] += 1\n",
    "                            \n",
    "    return aa_codon_counts, aa_structure_counts\n",
    "\n",
    "\n",
    "def print_chi_squared_results(data, significance_level = 0.05):\n",
    "    \"\"\"Perform chi-squared test and return the results\"\"\"\n",
    "    # to test if the structures and codons are significantly\n",
    "    # define the significance threshold\n",
    "    # here no bonferoni correction is applied since the hypotheses test are quite small\n",
    "    # store statistical test results in a dictionary\n",
    "    results_values = {}\n",
    "    results_print = {}\n",
    "    \n",
    "    # loop over the list of codons\n",
    "    for aa, codons in standard_codons.items():\n",
    "        # get the frequencies of the codons in the amino acid for a structure to test for significance\n",
    "        observed_frequencies = []\n",
    "        for structure in ['Helix', 'Coil', 'Sheet']:\n",
    "            observed_frequencies.append([data[aa][structure].get(codon, 0) for codon in codons])\n",
    "    \n",
    "        # transform the list of freuqencies to an array, need for chi2 test\n",
    "        observed_frequencies_array = np.array(observed_frequencies)\n",
    "        \n",
    "        # perform the chi-squared test with scipy method\n",
    "        chi2, p_value, dof, expected = chi2_contingency(observed_frequencies_array)\n",
    "    \n",
    "        # for easier evaluation print the chi-square static results\n",
    "        # and if the frequency differences are significant\n",
    "        if p_value < significance_level:\n",
    "            significance_msg = 'Significant difference in distribution'\n",
    "        else:\n",
    "            significance_msg = 'No significant difference'\n",
    "\n",
    "        # Store the result with the message\n",
    "        results_values[aa] = (chi2, p_value, significance_msg)\n",
    "        # store the results for each amino acid\n",
    "        results_print[aa] = f\"{aa}: Chi-squared = {chi2:e}, p-value = {p_value:e} -> {significance_msg}\"\n",
    "\n",
    "    return results_values, results_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count codons and structures from the data provided\n",
    "aa_codon_counts, aa_structure_counts = count_codons(nustrudb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries to store kl divergence values and probabilities\n",
    "aa_kl_divergences = {}\n",
    "aa_overall_probs = {}\n",
    "aa_structure_probs = {'Helix': {}, 'Coil': {}, 'Sheet': {}}\n",
    "\n",
    "# loop over the amino acids and the counted codons for each of them\n",
    "for aa, codons_list in standard_codons.items():\n",
    "    # sume the codons that appear for any structure\n",
    "    # calculate the probability that a codon appears with any structure\n",
    "    # or the overall probability of a codon appearing with any structure\n",
    "    total_overall = sum(aa_codon_counts[aa].values())\n",
    "    aa_overall_probs[aa] = {codon: (aa_codon_counts[aa][codon] / total_overall) if total_overall else 0 for codon in codons_list}\n",
    "\n",
    "    for structure in ['Helix', 'Coil', 'Sheet']:\n",
    "        # then we calculate the probability that a codon occurs with one of the structures\n",
    "        total_structure = sum(aa_structure_counts[aa][structure].values())\n",
    "        aa_structure_probs[structure][aa] = {codon: (aa_structure_counts[aa][structure][codon] / total_structure) if total_structure else 0 for codon in codons_list}\n",
    "\n",
    "        # calculate KL divergence or entropy for each structure compared to overall\n",
    "        # we take the overall probability of a codon and the structure dependent probabilty\n",
    "        # by that two lists of probabilities can be used to calculate the entropy \n",
    "        # this is done for each amino acid and not for individual codons\n",
    "        overall_probs_list = [aa_overall_probs[aa].get(codon, 0) for codon in codons_list]\n",
    "        structure_probs_list = [aa_structure_probs[structure][aa].get(codon, 0) for codon in codons_list]\n",
    "        kl_div = entropy(structure_probs_list, overall_probs_list) if total_structure else None\n",
    "\n",
    "        # store KL divergence values in a dictionary for each amino acid\n",
    "        if aa not in aa_kl_divergences:\n",
    "            aa_kl_divergences[aa] = {}\n",
    "        aa_kl_divergences[aa][structure] = kl_div\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the probabilities for each synonymous codon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create line plots for all 20 amino acids and their probabilites\n",
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(20, 20), sharey=False)\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "# for each synonymous codon plot the probabilities overall vs for each structure\n",
    "for ax, (aa, codons) in zip(axes, standard_codons.items()):\n",
    "    overall_probs = [aa_overall_probs[aa][codon] for codon in codons]\n",
    "    helix_probs = [aa_structure_probs['Helix'][aa].get(codon, 0) for codon in codons]\n",
    "    sheet_probs = [aa_structure_probs['Sheet'][aa].get(codon, 0) for codon in codons]\n",
    "    coil_probs = [aa_structure_probs['Coil'][aa].get(codon, 0) for codon in codons]\n",
    "\n",
    "    ax.plot(codons, overall_probs, label='Overall', marker='o', color='red')\n",
    "    ax.plot(codons, helix_probs, label='Helix', marker='o', color='orange', alpha=0.6)\n",
    "    ax.plot(codons, sheet_probs, label='Sheet', marker='o', color='lightgreen', alpha=0.6)\n",
    "    ax.plot(codons, coil_probs, label='Coil', marker='o', color='coral', alpha=0.6)\n",
    "    \n",
    "    ax.set_ylim(0, 0.8)\n",
    "    ax.set_title(f'{aa} Codon Usage')\n",
    "    ax.set_xlabel('Codons')\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "if savefig:\n",
    "    plt.savefig('pdb_codon_probabilities_across_structures.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the KL divergence for each amino acid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the KL divergence dictionary\n",
    "kl_df = pd.DataFrame.from_dict(aa_kl_divergences, orient='index').fillna(0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(kl_df, annot=False, cmap='viridis', linewidths=0.5)\n",
    "plt.xlabel('Secondary Structure')\n",
    "plt.ylabel('Amino Acid')\n",
    "if savefig:\n",
    "    plt.savefig('pdb_kl_divergence_heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the frequencies of codons in each secondary structure element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dictionaries to calculate the frequencies\n",
    "aa_structure_frequencies = {aa: {} for aa in standard_codons}\n",
    "\n",
    "# similar to when calculating the probabilities\n",
    "# the frequencies are calculated based on the counts of the codons and the counts for a structure\n",
    "for aa, structures in aa_structure_counts.items():\n",
    "    for structure_type, counts in structures.items():\n",
    "        # get the total of the structure and calculate the frequency\n",
    "        total = sum(counts.values())\n",
    "        aa_structure_frequencies[aa][structure_type] = {codon: count / total for codon, count in counts.items()}\n",
    "\n",
    "# prepare the data for plotting by storing the individual frequencies for each structure type\n",
    "list_of_codon_frequencies = []\n",
    "\n",
    "# loop over the codons of each amino acid and structure\n",
    "for aa, structures in aa_structure_frequencies.items():\n",
    "    # then loop over each synonymous codon for the amino acid and get the frequencies of each structure\n",
    "    codons = standard_codons[aa]\n",
    "    for codon in codons:\n",
    "        helix_freq = structures['Helix'].get(codon, 0)\n",
    "        coil_freq = structures['Coil'].get(codon, 0)\n",
    "        sheet_freq = structures['Sheet'].get(codon, 0)\n",
    "\n",
    "        # append each structure frequency of codons independently\n",
    "        list_of_codon_frequencies.append({'Amino Acid': aa, 'Codon': codon, 'Structure': 'Helix', 'Frequency': helix_freq})\n",
    "        list_of_codon_frequencies.append({'Amino Acid': aa, 'Codon': codon, 'Structure': 'Coil', 'Frequency': coil_freq})\n",
    "        list_of_codon_frequencies.append({'Amino Acid': aa, 'Codon': codon, 'Structure': 'Sheet', 'Frequency': sheet_freq})\n",
    "\n",
    "# create a dataframe which makes it easier to plot the data\n",
    "df_of_codon_frequencies = pd.DataFrame(list_of_codon_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the frequencies for each synonymous codon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the codon distributions\n",
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(20, 20), sharey=True)\n",
    "fig.suptitle('Codon Frequency Distributions Across Structures for Each Amino Acid', fontsize=16)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# get all amino acids\n",
    "amino_acids = standard_codons.keys()\n",
    "\n",
    "# for each synonymous codon plot the frequencies for each structure\n",
    "for idx, aa in enumerate(amino_acids):\n",
    "    subset = df_of_codon_frequencies[df_of_codon_frequencies['Amino Acid'] == aa]\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    barplot = sns.barplot(ax=ax, x='Codon', y='Frequency', hue='Structure', data=subset, palette='viridis')\n",
    "    ax.set_title(aa)\n",
    "    ax.set_xlabel('Codons')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "if savefig:\n",
    "    plt.savefig('pdb_codon_frequencies_across_structures.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the results to see which amino acids show a significant frequencies between the structures\n",
    "_, chi_squared_summary = print_chi_squared_results(data=aa_structure_counts)\n",
    "for result in chi_squared_summary.values():\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation with Random sampling to test if the frequencies for the structure elements and codons are significant for subgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the dataaset is so large, random sampling can help to see if the frequencies in codons and structures is still true for a random subset of samples. This minimzes statistical errors drawn from the large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sample(df_sample):\n",
    "    \"\"\"Calculate frequencies for each sample\"\"\"\n",
    "    # count codons and structures from the data provided\n",
    "    sample_aa_codon_counts, sample_aa_structure_counts = count_codons(df_sample)\n",
    "    \n",
    "    return sample_aa_structure_counts\n",
    "\n",
    "sample_size = 10  # set sample size for cross validation analysis\n",
    "number_of_samples = 20  # number of times to perform cross validation\n",
    "\n",
    "# we store the frequencies for all samples\n",
    "all_samples_counts = []\n",
    "\n",
    "for _ in range(number_of_samples):\n",
    "    # collect samples and calculate the frequencies\n",
    "    sample = nustrudb.sample(n=sample_size, random_state=_) \n",
    "    sample_counts = analyze_sample(sample) # get the frequencies for each sample\n",
    "    all_samples_counts.append(sample_counts)\n",
    "\n",
    "chi_squared_results_all_samples = [print_chi_squared_results(sample_counts)[0] for sample_counts in all_samples_counts]\n",
    "\n",
    "# summarize results across all samples\n",
    "aggregated_results = {aa: {'significant': 0, 'non_significant': 0} for aa in standard_codons}\n",
    "\n",
    "# count the number of times the frequencies were significantly different\n",
    "significance_level = 0.05\n",
    "for chi_squared_summary in chi_squared_results_all_samples:\n",
    "    for aa, result in chi_squared_summary.items():\n",
    "        if result[1] < significance_level:\n",
    "            aggregated_results[aa]['significant'] += 1\n",
    "        else:\n",
    "            aggregated_results[aa]['non_significant'] += 1\n",
    "\n",
    "# print the results of cross validation test\n",
    "for aa, freqs in aggregated_results.items():\n",
    "    print(f\"{aa}: {counts['significant']} out of {number_of_samples} samples showed significant difference in distribution\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CodonFold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
