{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import uuid\n",
    "import pickle\n",
    "import ast\n",
    "import os\n",
    "\n",
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and map the Codon rarity at each position of a multiple sequence alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the codon rarity at each position of a multiple sequence alignment:\n",
    "CRS = Codon Rarity Score, AA = Amino Acid, occ = Occurence, f_c = Frequency of codon, len = Length, aln = Alignment, gaps = Gaps, n_aln = Number of sequences in the alignment\n",
    "$$ CRS_{column}= {\\sum \\limits _{AA_{AA}} ^{n_{aln}}(\\sum \\limits _{occ=1} ^{n_{aln}} {AA_{occ}} * f_c) \\over {len_{total}(alignment)} - (gaps)} $$\n",
    "$$ f_c = { \\sum n_c \\over \\sum n_{AA} } * { 1 \\over n_{cAA} } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set data to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig = True # define if figures should be saved\n",
    "\n",
    "# assign the paths to the files need for the analysis\n",
    "alignment_file = \"/Example/examples_family/example_fam1_aln.fasta\" \n",
    "nustrudb =  \"/Example/examples_family/example_fam1_nustrudb.csv\"\n",
    "output_path = \"/Example/examples_family/\"\n",
    "\n",
    "# get a working name from the input file (e.g. protein family name) to use in the output files\n",
    "working_name = os.path.basename(alignment_file)\n",
    "\n",
    "nt_fasta_file = None  # nucleotide sequences in fasta format (optional, so no extra file will be created)\n",
    "\n",
    "# for the temporary created files, like the nucleotide sequences, create a unique job_id\n",
    "job_id = uuid.uuid4()\n",
    "\n",
    "# read the nucleotide structure database as csv\n",
    "nustrudb = pd.read_csv(nustrudb)\n",
    "\n",
    "# read the protein fasta alignment and nucleotide fasta sequences if provided\n",
    "protein_alignment = AlignIO.read(alignment_file, \"fasta\")\n",
    "if nt_fasta_file is not None:\n",
    "    nucleotide_sequences = SeqIO.parse(nt_fasta_file, \"fasta\")\n",
    "else:\n",
    "    # else create a temporary file with the nucleotide sequences corresponding to the protein sequences\n",
    "    for record in protein_alignment:\n",
    "        try:\n",
    "            # get the nucleotide id and sequence from the nustrudb\n",
    "            # and write the id and sequence to a temporary file in the defined output path\n",
    "            nucleotide_id = nustrudb.loc[nustrudb[\"primary_id\"] == record.id][\"nucleotide_id\"].values[0]\n",
    "            nucleotide_sequence = nustrudb.loc[nustrudb[\"primary_id\"] == record.id][\"nucleotide_sequence\"].values[0]\n",
    "            with open(f\"{output_path}/{job_id}_nucleotide_sequences.fasta\", \"a\") as f:\n",
    "                f.write(f\">{nucleotide_id}\\n{nucleotide_sequence}\\n\")\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # then read the temporary created nucleotide sequences\n",
    "    nucleotide_sequences = SeqIO.parse(f\"{output_path}/{job_id}_nucleotide_sequences.fasta\", \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_array(fasta, align_to=None, codon=False):\n",
    "    \"\"\"Converts a fasta file to a numpy array\"\"\"\n",
    "    # set empty lists to store the sequences and ids\n",
    "    all_seqs = []\n",
    "    all_ids = []\n",
    "    \n",
    "    if codon:\n",
    "        # if the sequences are nucleotide sequences and codons should be used\n",
    "        # then split the sequences into codons for each sequence in the fasta file\n",
    "        for (ind,record) in enumerate(fasta):\n",
    "            all_seqs.append(list(str(record.seq)))\n",
    "            all_seqs[ind] = [''.join(map(str, all_seqs[ind][i:i+3])) for i in range(0, len(all_seqs[ind]), 3)]\n",
    "            \n",
    "    else:         \n",
    "        # else just append the sequences and ids to the lists \n",
    "        # this can be done always for protein sequences  \n",
    "        for record in fasta:\n",
    "            all_seqs.append(list(str(record.seq)))\n",
    "            all_ids.append(record.id)\n",
    "        \n",
    "        # convert the sequences to a numpy array\n",
    "        all_seqs = np.array(all_seqs)\n",
    "\n",
    "    if align_to is not None:\n",
    "        # if an alignment is provided, then insert gaps in the sequences where gaps are in the alignment\n",
    "        # get the gap positions in the alignment and create a numpy array as a mask\n",
    "        gap_indeces = np.where(align_to == '-')\n",
    "        \n",
    "        # loop through the gap positions and insert a gap in the sequences\n",
    "        for gap_index in zip(gap_indeces[0], gap_indeces[1]):\n",
    "            # insert the gap index at the correpsonding position in the sequences\n",
    "            # since we align the codons we use 3 dashes for a gap to show nucleotide triplets\n",
    "            all_seqs[gap_index[0]].insert(gap_index[1], '---')\n",
    "        \n",
    "        # convert the aligned sequences with gaps to a numpy array\n",
    "        all_seqs = np.array(all_seqs)\n",
    "        # deleting stop codons as no protein assigned to them\n",
    "        all_seqs = np.delete(all_seqs, -1, axis=1)\n",
    "    \n",
    "    # reshape the ids to a numpy array according to the number of sequences (one column)\n",
    "    all_ids = np.array(all_ids).reshape(len(all_ids), 1)\n",
    "    \n",
    "    return all_seqs\n",
    "\n",
    "def filter_columns_by_gap_threshold(seq_arr, threshold=0.5):\n",
    "    \"\"\"Filter columns in a sequence array based on a gap threshold\"\"\"\n",
    "    # get the number of rows in the sequence array\n",
    "    n_rows = seq_arr.shape[0]\n",
    "    # create empty lists to store the valid and deleted columns\n",
    "    valid_columns = []\n",
    "    deleted_columns = []\n",
    "    \n",
    "    # Iterate through each column index\n",
    "    for col_index in range(seq_arr.shape[1]):\n",
    "        gap_count = np.sum(seq_arr[:, col_index] == 0)\n",
    "        gap_percentage = gap_count / n_rows\n",
    "        \n",
    "        # Append column index based on gap percentage\n",
    "        if gap_percentage <= threshold:\n",
    "            valid_columns.append(col_index)\n",
    "        else:\n",
    "            deleted_columns.append(col_index)\n",
    "    \n",
    "    # get all rows and only the valid columns where the gap percentage is below the threshold\n",
    "    filtered_seq_arr = seq_arr[:, valid_columns]\n",
    "    \n",
    "    return filtered_seq_arr, deleted_columns\n",
    "\n",
    "def cub_msa_table(prot_seq_arr=None, cod_seq_arr=None):\n",
    "    \"\"\"Create a codon usage bias table for the multiple sequence alignment\"\"\"\n",
    "    cub_table = {\n",
    "    # '*': {'TAA': None, 'TAG': None, 'TGA': None}, ignoring stop codons\n",
    "    'A': {'GCA': None, 'GCC': None, 'GCG': None, 'GCT': None},\n",
    "    'C': {'TGC': None, 'TGT': None},\n",
    "    'D': {'GAC': None, 'GAT': None},\n",
    "    'E': {'GAA': None, 'GAG': None},\n",
    "    'F': {'TTC': None, 'TTT': None},\n",
    "    'G': {'GGA': None, 'GGC': None, 'GGG': None, 'GGT': None},\n",
    "    'H': {'CAC': None, 'CAT': None},\n",
    "    'I': {'ATA': None, 'ATC': None, 'ATT': None},\n",
    "    'K': {'AAA': None, 'AAG': None},\n",
    "    'L': {'CTA': None, 'CTC': None, 'CTG': None, 'CTT': None, 'TTA': None, 'TTG': None},\n",
    "    'M': {'ATG': None},\n",
    "    'N': {'AAC': None, 'AAT': None},\n",
    "    'P': {'CCA': None, 'CCC': None, 'CCG': None, 'CCT': None},\n",
    "    'Q': {'CAA': None, 'CAG': None},\n",
    "    'R': {'AGA': None, 'AGG': None, 'CGA': None, 'CGC': None, 'CGG': None, 'CGT': None},\n",
    "    'S': {'AGC': None, 'AGT': None, 'TCA': None, 'TCC': None, 'TCG': None, 'TCT': None},\n",
    "    'T': {'ACA': None, 'ACC': None, 'ACG': None, 'ACT': None},\n",
    "    'V': {'GTA': None, 'GTC': None, 'GTG': None, 'GTT': None},\n",
    "    'W': {'TGG': None},\n",
    "    'Y': {'TAC': None, 'TAT': None}}\n",
    "    \n",
    "    for aa in cub_table.keys():\n",
    "        # loop through the amino acids and codons in the cub table and calculate the frequency\n",
    "        # n_AA is the number of occurences of the amino acid in the protein sequence\n",
    "        n_AA = np.count_nonzero(prot_seq_arr == aa)\n",
    "                \n",
    "        # nc_AA is the number of synonyomous codons for the amino acid\n",
    "        nc_AA = len(cub_table[aa].keys())\n",
    "        \n",
    "        for codon in cub_table[aa].keys():\n",
    "            # now for each codon a frequency based on the alignment is calculated\n",
    "            # nc is the number of occurences of the codon in the in the sequences\n",
    "            nc = np.count_nonzero(cod_seq_arr == codon)\n",
    "            \n",
    "            # fc is the frequency of the codon in the alignment\n",
    "            # it is calculated by dividing the number of occurences of the codon by the number of occurences of the amino acid\n",
    "            # then its normalized by the number of synonymous codons\n",
    "            fc =(nc / n_AA) * 1/nc_AA\n",
    "\n",
    "            # round the frequency to 6 decimal places and create an cub table with the frequencies based on the msa\n",
    "            cub_table[aa][codon] = round(fc,6)\n",
    "        \n",
    "    return cub_table\n",
    "\n",
    "def map_rarity(protein_alignment, nustrudb, cu_table):\n",
    "    \"\"\"Map the rarity of the codons to the protein alignment\"\"\"\n",
    "    codon_position_start = 0\n",
    "    \n",
    "    # calculate amino acid occurence in the alignment\n",
    "    # and create a dictionary with the amino acid and its occurence\n",
    "    unique_aa, aa_counts = np.unique(protein_alignment, return_counts=True)\n",
    "    aa_counts = dict(zip(unique_aa, aa_counts))\n",
    "    \n",
    "    # create an empty matrix to store the rarity values\n",
    "    alignment_value_matrix = np.zeros((len(protein_alignment), len(protein_alignment[0])))\n",
    "    seq_name = [seq.id for seq in protein_alignment] # get the sequence names or ids from the alignment\n",
    "    seq_pos = [i for i in range(len(protein_alignment[0]))] # get the sequence positions (with gaps)\n",
    "\n",
    "    # keep track of the position in the alignment for each sequence\n",
    "    # this is needed to adjust the position based on the gaps in the alignment\n",
    "    # so keeps track of the gaps in the alignment\n",
    "    pos_count_dict = {seq_name[i]: 0 for i in range(len(seq_name))}\n",
    "    \n",
    "    # loop over the sequences in the alignment\n",
    "    for position in range(len(protein_alignment[0])):\n",
    "        # loop over the amino acids and sequences in the alignment\n",
    "        for i, (aa, seq) in enumerate(zip(protein_alignment[:,position],seq_name)):\n",
    "            # if the amino acid is a gap, then set the rarity to 0\n",
    "            # else calculate the rarity based on the codon usage table\n",
    "            if aa == '-':\n",
    "                # add gaps to the alignment value matrix\n",
    "                alignment_value_matrix[i, position] = 0 # gaps have no information\n",
    "                pos_count_dict[seq] += 1 # count the gaps for each sequence\n",
    "            else:\n",
    "                # adjust the position in the nucleotide sequence based on the gaps in the alignment\n",
    "                prot_position = pos_count_dict[seq]\n",
    "                position_adj = position - prot_position \n",
    "                \n",
    "                # get the nucleotide sequence from the nustrudb\n",
    "                sequence = nustrudb[nustrudb[\"primary_id\"] == seq][\"nucleotide_sequence\"].values[0]\n",
    "                # set the rarity value based on the codon usage table\n",
    "                # since the codon usage table is based on codons, we need to adjust the position by 3\n",
    "                # the values are then stored in the equivalent position in the alignment value matrix\n",
    "                alignment_value_matrix[i, position] = cu_table[aa][sequence[position_adj*3:position_adj*3+3].upper()]\n",
    "\n",
    "    # calculate the mean rarity of the residues in the alignment\n",
    "    # divide the sum of the rarity values in a column by the number of sequences\n",
    "    # subtract the number of gaps in the column from the number of sequences\n",
    "    # vertical mean of the rarity values in a column (column mean)  \n",
    "    residue_mean = []\n",
    "    for i, col_mean in enumerate(np.sum(alignment_value_matrix, axis=0)):\n",
    "        residue_mean.append(col_mean / (len(seq_name) - np.count_nonzero(alignment_value_matrix[:, i] == 0)))\n",
    "\n",
    "    # calculate the max rarity of the residues in the alignment\n",
    "    # vertical max of the rarity values in a column\n",
    "    residue_max = []\n",
    "    for col_max in np.max(alignment_value_matrix, axis=0):\n",
    "        residue_max.append(col_max)\n",
    "    \n",
    "    return alignment_value_matrix, seq_name, seq_pos, residue_mean, residue_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform alignment and sequences to arrays and align the gaps if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the protein and nucleotide sequences to numpy arrays\n",
    "# nucleotide sequences are aligned to the protein sequences and split into codons\n",
    "all_seqs_protein = fasta_to_array(protein_alignment)\n",
    "all_seqs_nt = fasta_to_array(fasta=nucleotide_sequences, align_to=all_seqs_protein, codon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the codon frequency for each amino acid based on the alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ f_c = { \\sum n_c \\over \\sum n_{AA} } * { 1 \\over n_{cAA} } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rarity of the codons in the alignment based on the formula\n",
    "cub_msa_table = cub_msa_table(prot_seq_arr=all_seqs_protein, cod_seq_arr=all_seqs_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with the rarity values based on the alignment\n",
    "# this is needed for other scripts like the fold class analysis\n",
    "merged_dict = {key: value for codon in cub_msa_table.values() for key, value in codon.items()}\n",
    "\n",
    "# store the rarity values in a pickle file which can be used in other scripts\n",
    "with open(f\"{output_path}/{working_name}_cub_msa_table.pkl\", \"wb\") as f:\n",
    "    pickle.dump(merged_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Codon Rarity Score for each position of the alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ CRS_{column}= {\\sum \\limits _{AA_{AA}} ^{n_{aln}}(\\sum \\limits _{occ=1} ^{n_{aln}} {AA_{occ}} * f_c) \\over {len_{total}(alignment)} - (gaps)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the rarity values to the alignment and create a numpy array based on the positions\n",
    "# calculate the mean rarity of the residues and columns in the alignment\n",
    "# also get the sequence names and positions for each row in the alignment\n",
    "alignment_value_matrix, seq_name, seq_pos, residue_mean, residue_max = map_rarity(protein_alignment, nustrudb, cub_msa_table)\n",
    "\n",
    "# sort the CRS matrix and flip it to get the sorted values\n",
    "# just for visualization purposes later\n",
    "sorted_alignment_value_matrix = np.sort(alignment_value_matrix, axis=0)\n",
    "sorted_alignment_value_matrix = np.flip(sorted_alignment_value_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the columns in the alignment based on a gap threshold, here 50%\n",
    "# save the deleted columns to a list\n",
    "alignment_value_matrix_filtered,deleted_columns = filter_columns_by_gap_threshold(alignment_value_matrix)\n",
    "sorted_alignment_value_matrix_filtered,deleted_columns = filter_columns_by_gap_threshold(sorted_alignment_value_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the deleted columns to filter the sequence positions, residue mean and residue max\n",
    "# this aligns all values to the filtered alignment matrix\n",
    "for index in sorted(deleted_columns, reverse=True):\n",
    "    del seq_pos[index]\n",
    "    del residue_max[index]\n",
    "    del residue_mean[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sequence positions for the filtered alignment matrix\n",
    "# the old seq_pos can be also used\n",
    "seq_pos_new = [i for i in range(len(residue_max))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Codon Rarity Score for each position of the alignment in MSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The window is set to 10 positions, but it can be changed to any value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe with the sequence positions and the residue mean\n",
    "df = pd.DataFrame({\n",
    "    'x': seq_pos,\n",
    "    'y': residue_mean\n",
    "})\n",
    "\n",
    "# Apply a Savitzky-Golay filter to the residue mean values\n",
    "# this is done to smooth the curve and remove noise\n",
    "# the window size is 10 and the polynomial order is 3\n",
    "df['smoothed_y'] = savgol_filter(df['y'], 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the codon rarity matrix as a heatmap and the CRS mean per column/position as a line plot\n",
    "# used plotly for the heatmap and line plot as it is interactive and subplots are easier to create\n",
    "fig1 = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "fig1.add_trace((go.Heatmap(z=alignment_value_matrix_filtered, y=seq_name, colorscale=\"blues\", showlegend=False)), row=3, col=1)\n",
    "fig1.add_trace((go.Heatmap(z=sorted_alignment_value_matrix_filtered, y=seq_name, colorscale=\"blues\")), row=2, col=1)\n",
    "fig1.add_trace((go.Scatter(x=seq_pos_new, y=df['smoothed_y'], mode=\"lines\", line=dict(color=\"navy\"))), row=1, col=1)\n",
    "fig1['layout']['yaxis1']['visible']=True\n",
    "fig1['layout']['yaxis2']['visible']=False\n",
    "fig1['layout']['yaxis3']['visible']=False\n",
    "\n",
    "if savefig:\n",
    "    fig1.write_image(f\"{output_path}/{working_name}_codon_rarity_heatmap.png\", scale=2)\n",
    "    fig1.write_html(f\"{output_path}/{working_name}_codon_rarity_heatmap.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the correlation between the smoothed Y and the secondary structure frequencies as a log odds ratio (rare codons and secondary structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define new functions for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secondary_structure(seq_names, aln_prot_arr, nustrudb):\n",
    "    \"\"\"Create a list with the aligned secondary structure arrays\"\"\"\n",
    "    aligned_secstru_list = []\n",
    "\n",
    "    for seq in seq_names:\n",
    "        # Retrieve the secondary structure dictionary for the current sequence\n",
    "        secstru_dict = nustrudb[nustrudb[\"primary_id\"] == seq][\"secondary_structure\"].values[0]\n",
    "        \n",
    "        secstru_dict = ast.literal_eval(secstru_dict)\n",
    "        # Convert the dictionary to a list that aligns with the protein sequence length\n",
    "        max_pos = max(secstru_dict.keys())\n",
    "        secstru_list = ['-' for _ in range(max_pos)]\n",
    "        for pos, ss in secstru_dict.items():\n",
    "            secstru_list[pos - 1] = ss  # Adjust for 1-based to 0-based indexing\n",
    "        \n",
    "        # Align the secondary structure list with the protein alignment\n",
    "        aligned_secstru = []\n",
    "        secstru_idx = 0\n",
    "        \n",
    "        # previously gap postions were filtered out with more than 50% gaps\n",
    "        # however since there are still gaps present in the alignment, it is necessary to adjust the secondary structure list\n",
    "        for aa in aln_prot_arr[seq_names.index(seq)]:\n",
    "            if aa == '-': # if gap, add a gap to the secondary structure list\n",
    "                aligned_secstru.append('0')\n",
    "            else: # if not a gap, add the secondary structure element\n",
    "                aligned_secstru.append(secstru_list[secstru_idx])\n",
    "                secstru_idx += 1\n",
    "        \n",
    "        # append the aligned secondary structure list to the list of lists\n",
    "        aligned_secstru_list.append(aligned_secstru) \n",
    "    \n",
    "    # convert the list of lists to a numpy array\n",
    "    # this makes it easier to work with the data later on and to plot the data\n",
    "    return np.array(aligned_secstru_list)\n",
    "\n",
    "def secstru_to_numeric(secstru_arr):\n",
    "    \"\"\"Convert secondary structure elements to numeric values for plotting\"\"\"\n",
    "    # store the numeric secondary structure arrays in a list\n",
    "    secstru_numeric = []\n",
    "    \n",
    "    for secstru in secstru_arr:\n",
    "        # loop through each secondary structure element in the array and append the numeric value to a new list\n",
    "        # the secondary structure elements are aggregated into three categories: helix, sheet, and coil\n",
    "        numeric_seq = []\n",
    "        for element in secstru:\n",
    "            if element == 'H' or element == 'I' or element == 'G':\n",
    "                numeric_seq.append(1)\n",
    "            elif element == 'E' or element == 'B':\n",
    "                numeric_seq.append(2)\n",
    "            elif element == '-' or element == 'T' or element == 'S':\n",
    "                numeric_seq.append(3)\n",
    "            elif element == '0': # previously gaps were assigned to 0 and are just kept as 0\n",
    "                numeric_seq.append(0)\n",
    "            else: # if an unknown secondary structure element is present, assign it to 0 (normally not the case)\n",
    "                numeric_seq.append(0)\n",
    "        \n",
    "        # append the numeric secondary structure array to the list of numeric arrays\n",
    "        secstru_numeric.append(numeric_seq)\n",
    "        \n",
    "    # convert the list of numeric arrays to a numpy array\n",
    "    return np.array(secstru_numeric)    \n",
    "\n",
    "def calculate_probabilities(secstru_numeric, rarity_matrix, rare_threshold):\n",
    "    \"\"\"Calculate the probabilities of rare codons in each secondary structure element\"\"\"\n",
    "    rare_codon_numeric = rarity_matrix < rare_threshold # the definition of rare codons is based on the rarity threshold\n",
    "    probabilities = [] # list to store the probabilities for each position\n",
    "\n",
    "    for pos in range(secstru_numeric.shape[1]):\n",
    "        # loop over each position in the alignment\n",
    "        prob_pos = {} # probability dictionary for the current position\n",
    "        \n",
    "        for ss_type in [1, 2, 3]:  # H, E, and Coil\n",
    "            # loop over each secondary structure element and calculate the probabilities\n",
    "            # calculate the joint probability of a secondary structure element and a rare codon at the current position\n",
    "\n",
    "            \n",
    "            # calculate the probabilities for each secondary structure element at the current position\n",
    "            # meaning the independent probability of a secondary structure element\n",
    "            prob_ss = np.mean(secstru_numeric[:, pos] == ss_type)\n",
    "            \n",
    "            # calculate the probability of a rare codon at the current position\n",
    "            # meaning the independent probability of a rare codon\n",
    "            prob_rare = np.mean(rare_codon_numeric[:, pos])\n",
    "            \n",
    "            # calculate the joint probability of a secondary structure element and a rare codon at the current position\n",
    "            joint_prob = np.mean((secstru_numeric[:, pos] == ss_type) & rare_codon_numeric[:, pos])\n",
    "\n",
    "            # store the probabilities in a dictionary\n",
    "            # for each position, the probabilities for each secondary structure element are stored\n",
    "            prob_pos[ss_type] = {\n",
    "                \"joint_prob\": joint_prob,\n",
    "                \"prob_ss\": prob_ss,\n",
    "                \"prob_rare\": prob_rare\n",
    "            }\n",
    "        # append the probabilities for the current position to the list of probabilities\n",
    "        probabilities.append(prob_pos)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "def calculate_odds_ratios(probabilities):\n",
    "    \"\"\"Calculate the odds ratios for each secondary structure element having a rare codon\"\"\"\n",
    "    odds_ratios = []\n",
    "\n",
    "    # loop over the probabilities for each position\n",
    "    for prob_pos in probabilities:\n",
    "        # store the odds ratios for each secondary structure element in a dictionary\n",
    "        odds_ratios_pos = {}\n",
    "        for ss_type in [1, 2, 3]:  # H, E, and Coil\n",
    "            joint_prob = prob_pos[ss_type][\"joint_prob\"]\n",
    "            prob_ss = prob_pos[ss_type][\"prob_ss\"]\n",
    "            prob_rare = prob_pos[ss_type][\"prob_rare\"]\n",
    "\n",
    "            try:\n",
    "                # calculate the odds ratio for each secondary structure element\n",
    "                odds_ratio = joint_prob / (prob_ss * prob_rare)\n",
    "            except:\n",
    "                odds_ratio = 0 # Handle division by zero\n",
    "\n",
    "            # assign the odds ratio to the dictionary for the current position and secondary structure element\n",
    "            odds_ratios_pos[ss_type] = odds_ratio\n",
    "        # append the odds ratios for the current position to the list of odds ratios\n",
    "        odds_ratios.append(odds_ratios_pos)\n",
    "    \n",
    "    return odds_ratios\n",
    "\n",
    "def log_scale_odds_ratios(odds_ratios):\n",
    "    \"\"\"\"Log transform the odds ratios\"\"\"\n",
    "    log_odds_ratios = []\n",
    "    \n",
    "    # loop over the odds ratios for each position\n",
    "    for odds in odds_ratios:\n",
    "        # store the log odds ratios in a dictionary\n",
    "        log_odds = {}\n",
    "        for key, value in odds.items():\n",
    "            log_odds[key] = np.log(value)\n",
    "        # append the log odds ratios for the current position to the list of log odds ratios\n",
    "        # same as before, only this time the odds ratios are log transformed\n",
    "        log_odds_ratios.append(log_odds)\n",
    "    return log_odds_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the log odds ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the secondary structure for the protein sequences\n",
    "aligned_secstru_arr = get_secondary_structure(seq_name, all_seqs_protein, nustrudb)\n",
    "\n",
    "# convert the secondary structure elements to numeric values\n",
    "secstru_numeric = secstru_to_numeric(aligned_secstru_arr)\n",
    "\n",
    "# filter the columns in the alignment based on a gap threshold from previously\n",
    "secstru_numeric_ng = np.delete(secstru_numeric, deleted_columns, axis=1)\n",
    "\n",
    "# calculate the probabilities of rare codons in each secondary structure element\n",
    "# get the log odds of having a rare codon together with a secondary structure element\n",
    "rare_threshold = 0.3 # Define your threshold for rarity\n",
    "probabilities = calculate_probabilities(secstru_numeric_ng, alignment_value_matrix, rare_threshold)\n",
    "odds_ratios = calculate_odds_ratios(probabilities)\n",
    "    \n",
    "# log transform the odds ratios\n",
    "log_odds_ratios = log_scale_odds_ratios(odds_ratios)\n",
    "\n",
    "# create an array with the positions for the secondary structure elements\n",
    "positions = np.arange(len(log_odds_ratios))\n",
    "\n",
    "# create lists of the log odds ratios for each secondary structure element\n",
    "odds_H = [or_dict[1] for or_dict in log_odds_ratios]\n",
    "odds_E = [or_dict[2] for or_dict in log_odds_ratios]\n",
    "odds_C = [or_dict[3] for or_dict in log_odds_ratios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the bar width for the plot\n",
    "bar_width = 0.8\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "ax.bar(positions, odds_H, color='cadetblue', width=bar_width, label='Helix (H)')\n",
    "ax.bar(positions, odds_E, color='coral', width=bar_width, label='Sheet (E)')\n",
    "ax.bar(positions, odds_C, color='mediumseagreen', width=bar_width, label='Coil (C)')\n",
    "# ax.plot(positions, df['smoothed_y'], label='Smoothed Y', linewidth=2, linestyle='--', color='blue')\n",
    "\n",
    "ax.set_xlim([-5, len(positions)])\n",
    "ax.set_xlabel('Position')\n",
    "ax.set_ylabel('Log Odds Ratio')\n",
    "ax.legend()\n",
    "ax.set_xticks(positions[::5])\n",
    "\n",
    "plt.tight_layout()\n",
    "if savefig:\n",
    "    plt.savefig(f\"{output_path}/{working_name}_log_odds_ratios.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the consesus secondary structure of the alignment with the Codon Rarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the consensus secondary structure for the protein sequences\n",
    "consensus_numeric = []\n",
    "\n",
    "# loop over the positions in the secondary structure numeric array\n",
    "for pos in range(secstru_numeric_ng.shape[1]):\n",
    "    # get the secondary structure elements at the current position\n",
    "    pos_elements = secstru_numeric_ng[:, pos]\n",
    "    \n",
    "    # use the Counter class to get the most common secondary structure element at the current position\n",
    "    most_common = Counter(pos_elements).most_common(1)[0][0]\n",
    "    # append the most common secondary structure element to the consensus list\n",
    "    consensus_numeric.append(most_common)\n",
    "\n",
    "# create a plot with the consensus secondary structure and the smoothed CRS mean\n",
    "positions = np.arange(len(consensus_numeric))\n",
    "fig, ax1 = plt.subplots(figsize=(14, 3)) \n",
    "\n",
    "colors = {1: 'cadetblue', 2: 'coral', 3: 'mediumseagreen', 0: 'lightgray'}\n",
    "labels = {1: 'Helix', 2: 'Sheet', 3: 'Coil', 0: 'Gap'}\n",
    "\n",
    "for pos in positions:\n",
    "    ax1.bar(pos, 1, color=colors[consensus_numeric[pos]], edgecolor='none', width=1)\n",
    "\n",
    "ax1.set_xticks(positions[::10]) \n",
    "ax1.set_xticklabels(positions[::10] + 1, rotation=90)\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xlim([-1, len(consensus_numeric)])\n",
    "ax1.set_xlabel('Position')\n",
    "ax1.grid(False)\n",
    "\n",
    "legend_elements = [plt.Line2D([0], [0], color=colors[i], lw=6, label=labels[i]) for i in [1, 2, 3, 0]]\n",
    "\n",
    "ax2 = ax1.twinx() \n",
    "ax2.plot(seq_pos_new, df['smoothed_y'], color=\"navy\", linewidth=2, linestyle='-')\n",
    "ax2.tick_params(axis='y', labelcolor=\"navy\")\n",
    "ax2.legend(bbox_to_anchor=(0.6, 1.3), ncol=5, handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "if savefig:\n",
    "    plt.savefig(f\"{output_path}/{working_name}_consensus.png\", dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CodonTree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
